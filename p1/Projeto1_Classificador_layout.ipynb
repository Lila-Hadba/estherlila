{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ciência dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Esther Dagir\n",
    "\n",
    "Nome: Lila Hadba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atenção:** Serão permitidos grupos de três pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisarão fazer um questionário de avaliação de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-af11184d7c8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#!pip install emoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0memoji\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mUNICODE_EMOJI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_rows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m13\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'emoji'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from math import*\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "#!pip install emoji\n",
    "\n",
    "from emoji import UNICODE_EMOJI\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Netflix.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'Netflix.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'Não encontrei o arquivo {filename} aqui no diretório {os.getcwd()}, será que você não baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e não relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saiu da netflix? q sdd de full house! amo muit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mano, não tem mais nada p assistir na netflix ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@jornaloglobo vcs assistiram o filme, primeira...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  Categoria\n",
       "0  saiu da netflix? q sdd de full house! amo muit...          1\n",
       "1  rt @karolcaipira: gente vcs tem que entender u...          1\n",
       "2  rt @karolcaipira: gente vcs tem que entender u...          1\n",
       "3  mano, não tem mais nada p assistir na netflix ...          1\n",
       "4  @jornaloglobo vcs assistiram o filme, primeira...          1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @blogdadireita: min. damares alves quer pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rachwlgrwn no off eu fui até a terceira e se ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu quero julie e os fantasmas na netflix pra c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nunca vou perdoar a netflix https://t.co/ssrbk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seria demais querer que a @damaresalves e os e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  Categoria\n",
       "0  rt @blogdadireita: min. damares alves quer pro...          0\n",
       "1  @rachwlgrwn no off eu fui até a terceira e se ...          1\n",
       "2  eu quero julie e os fantasmas na netflix pra c...          1\n",
       "3  nunca vou perdoar a netflix https://t.co/ssrbk...          1\n",
       "4  seria demais querer que a @damaresalves e os e...          0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador automático de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça aqui uma descrição do seu produto e o que considerou como relevante ou não relevante na classificação dos tweets.\n",
    "\n",
    "\n",
    "\n",
    "Nosso produto é um serviço de streaming de filmes e séries. De uma escala de 0 a 2 temos que:\n",
    "0 é \"nada relevante\" - abrange tweets que não influenciam no desempenho da plataforma\n",
    "1 é \"relevante\" - tweets que são recomendações ou reinvidicações para a plataforma\n",
    "2 é \"muito relevante\" - todos os tweets que estão relacionados ao gosto positivamente e negativamente à plataforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @bunnyfeveer: esses dias estreou o filme mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>damares quer proibir filme da netflix acusado ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@elgwellm meu pai tá me pirraçando e até agora...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@pacefeco o que tem a ver a globo com a netfli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eu começo a ver umas coisa tão aleatória não n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>nada tira da minha cabeça que ela já sabia que...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>os militantes que cancelaram a netflix pelo fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>rt @craibeibe: inveja de você? kkkkkkkkkkkkkkk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>quero saber quando é q vou poder colocar as pi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>@boatosorg bolsonaristas já estão importando a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Categoria\n",
       "5    rt @bunnyfeveer: esses dias estreou o filme mi...          0\n",
       "8    damares quer proibir filme da netflix acusado ...          0\n",
       "9    @elgwellm meu pai tá me pirraçando e até agora...          0\n",
       "10   @pacefeco o que tem a ver a globo com a netfli...          0\n",
       "17   eu começo a ver umas coisa tão aleatória não n...          0\n",
       "..                                                 ...        ...\n",
       "290  nada tira da minha cabeça que ela já sabia que...          0\n",
       "294  os militantes que cancelaram a netflix pelo fi...          0\n",
       "295  rt @craibeibe: inveja de você? kkkkkkkkkkkkkkk...          0\n",
       "296  quero saber quando é q vou poder colocar as pi...          0\n",
       "299  @boatosorg bolsonaristas já estão importando a...          0\n",
       "\n",
       "[145 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#juntar num textao\n",
    "dfnaorelevante = train.loc[train['Categoria'] == 0]\n",
    "textao0 = \" \".join(dfnaorelevante.Treinamento)\n",
    "dfnaorelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt @bunnyfeveer: esses dias estreou o filme mi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>damares quer proibir filme da netflix acusado ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@elgwellm meu pai tá me pirraçando e até agora...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@pacefeco o que tem a ver a globo com a netfli...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>eu começo a ver umas coisa tão aleatória não n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>nada tira da minha cabeça que ela já sabia que...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>os militantes que cancelaram a netflix pelo fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>rt @craibeibe: inveja de você? kkkkkkkkkkkkkkk...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>quero saber quando é q vou poder colocar as pi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>@boatosorg bolsonaristas já estão importando a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Categoria\n",
       "5    rt @bunnyfeveer: esses dias estreou o filme mi...          0\n",
       "8    damares quer proibir filme da netflix acusado ...          0\n",
       "9    @elgwellm meu pai tá me pirraçando e até agora...          0\n",
       "10   @pacefeco o que tem a ver a globo com a netfli...          0\n",
       "17   eu começo a ver umas coisa tão aleatória não n...          0\n",
       "..                                                 ...        ...\n",
       "290  nada tira da minha cabeça que ela já sabia que...          0\n",
       "294  os militantes que cancelaram a netflix pelo fi...          0\n",
       "295  rt @craibeibe: inveja de você? kkkkkkkkkkkkkkk...          0\n",
       "296  quero saber quando é q vou poder colocar as pi...          0\n",
       "299  @boatosorg bolsonaristas já estão importando a...          0\n",
       "\n",
       "[145 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnaorelevante = train.loc[train['Categoria'] == 0]\n",
    "dfnaorelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntar num textao\n",
    "dfrelevante = train.loc[train['Categoria'] == 1]\n",
    "dfrelevante\n",
    "textao1 = \" \".join(dfrelevante.Treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saiu da netflix? q sdd de full house! amo muit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mano, não tem mais nada p assistir na netflix ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@jornaloglobo vcs assistiram o filme, primeira...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>rt @awaecharts: anne with an e na netflix chil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>rt @baptistafairy: eu tô muito sedenta pela se...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>netflix já foi melhor .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@netflixbrasil netflix querida, vê se consegue...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>rt @storyiaa: never say never votou pra netfli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Categoria\n",
       "0    saiu da netflix? q sdd de full house! amo muit...          1\n",
       "1    rt @karolcaipira: gente vcs tem que entender u...          1\n",
       "2    rt @karolcaipira: gente vcs tem que entender u...          1\n",
       "3    mano, não tem mais nada p assistir na netflix ...          1\n",
       "4    @jornaloglobo vcs assistiram o filme, primeira...          1\n",
       "..                                                 ...        ...\n",
       "291  rt @awaecharts: anne with an e na netflix chil...          1\n",
       "292  rt @baptistafairy: eu tô muito sedenta pela se...          1\n",
       "293                            netflix já foi melhor .          1\n",
       "297  @netflixbrasil netflix querida, vê se consegue...          1\n",
       "298  rt @storyiaa: never say never votou pra netfli...          1\n",
       "\n",
       "[155 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrelevante = train.loc[train['Categoria'] == 1]\n",
    "dfrelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfmuitorelevante = train.loc[train[\\'Categoria\\'] == 2]\\ndfmuitorelevante\\ntextao2 = \" \".join(dfmuitorelevante.Treinamento)'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#juntar num textao\n",
    "'''dfmuitorelevante = train.loc[train['Categoria'] == 2]\n",
    "dfmuitorelevante\n",
    "textao2 = \" \".join(dfmuitorelevante.Treinamento)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dfmuitorelevante = train.loc[train['Categoria'] == 2]\\ndfmuitorelevante\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dfmuitorelevante = train.loc[train['Categoria'] == 2]\n",
    "dfmuitorelevante'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.563786\n",
       "0    0.436214\n",
       "Name: Categoria, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Categoria'].value_counts(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador.\n",
    "Antes, foi realizado uma função para filtrar  os textos, trocando certos caracteres por espaço e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Função de limpeza muito simples que troca alguns sinais básicos por espaços\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_subbed = re.sub('http', '', text_subbed)\n",
    "    return text_subbed\n",
    "\n",
    "def is_emoji(a):\n",
    "    return a in UNICODE_EMOJI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensinando o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5      rt @bunnyfeveer esses dias estreou o filme mig...\n",
      "8      damares quer proibir filme da netflix acusado ...\n",
      "9      @elgwellm meu pai tá me pirraçando e até agora...\n",
      "10     @pacefeco o que tem a ver a globo com a netfli...\n",
      "17     eu começo a ver umas coisa tão aleatória não n...\n",
      "                             ...                        \n",
      "290    nada tira da minha cabeça que ela já sabia que...\n",
      "294    os militantes que cancelaram a netflix pelo fi...\n",
      "295    rt @craibeibe inveja de você kkkkkkkkkkkkkkkkk...\n",
      "296    quero saber quando é q vou poder colocar as pi...\n",
      "299    @boatosorg bolsonaristas já estão importando a...\n",
      "Name: Treinamento, Length: 145, dtype: object\n"
     ]
    }
   ],
   "source": [
    "netflix0limpo = dfnaorelevante['Treinamento'].apply(cleanup)\n",
    "\n",
    "print(netflix0limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_naorelevantes = []\n",
    "palavrasnaorelevantes = []\n",
    "for tt in netflix0limpo:\n",
    "    lista_naorelevantes.append(tt.split())\n",
    "    \n",
    "for a in lista_naorelevantes:\n",
    "    for b in a:\n",
    "        palavrasnaorelevantes.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      rt\n",
       "1            @bunnyfeveer\n",
       "2                   esses\n",
       "3                    dias\n",
       "4                 estreou\n",
       "              ...        \n",
       "3036           importando\n",
       "3037                    a\n",
       "3038                 fake\n",
       "3039               abaixo\n",
       "3040    s//tco/tnrpdhzlgj\n",
       "Length: 3041, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_0 = pd.Series(palavrasnaorelevantes)\n",
    "serie_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix        129\n",
       "a              104\n",
       "de              84\n",
       "que             76\n",
       "o               59\n",
       "              ... \n",
       "resto            1\n",
       "pois             1\n",
       "igualzinho       1\n",
       "história         1\n",
       "@sapphicute      1\n",
       "Length: 1266, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_naorelevante = serie_0.value_counts()\n",
    "tabela_naorelevante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      saiu da netflix q sdd de full house amo muitoo...\n",
      "1      rt @karolcaipira gente vcs tem que entender um...\n",
      "2      rt @karolcaipira gente vcs tem que entender um...\n",
      "3      mano não tem mais nada p assistir na netflix q...\n",
      "4      @jornaloglobo vcs assistiram o filme primeiram...\n",
      "                             ...                        \n",
      "291    rt @awaecharts anne with an e na netflix chile...\n",
      "292    rt @baptistafairy eu tô muito sedenta pela seg...\n",
      "293                               netflix já foi melhor \n",
      "297    @netflixbrasil netflix querida vê se consegue ...\n",
      "298    rt @storyiaa never say never votou pra netflix...\n",
      "Name: Treinamento, Length: 155, dtype: object\n"
     ]
    }
   ],
   "source": [
    "netflix1limpo = dfrelevante['Treinamento'].apply(cleanup)\n",
    "\n",
    "print(netflix1limpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_relevantes = []\n",
    "palavrasrelevantes = []\n",
    "for tt in netflix1limpo:\n",
    "    lista_relevantes.append(tt.split())\n",
    "    \n",
    "for a in lista_relevantes:\n",
    "    for b in a:\n",
    "        palavrasrelevantes.append(b)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    saiu\n",
       "1                      da\n",
       "2                 netflix\n",
       "3                       q\n",
       "4                     sdd\n",
       "              ...        \n",
       "2973                 meus\n",
       "2974            lencinhos\n",
       "2975                   de\n",
       "2976                papel\n",
       "2977    s//tco/edylx1xewt\n",
       "Length: 2978, dtype: object"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_1 = pd.Series(palavrasrelevantes)\n",
    "serie_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix         152\n",
       "a               107\n",
       "de               70\n",
       "e                62\n",
       "que              57\n",
       "               ... \n",
       "@rogwrspider      1\n",
       "lembrei           1\n",
       "kshsis            1\n",
       "ohantoms          1\n",
       "qui               1\n",
       "Length: 1156, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relevante = serie_1.value_counts()\n",
    "tabela_relevante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 1\n",
    "v = 400000 #palavras na lingua port"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculando Palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_palavras = tabela_naorelevante.sum() + tabela_relevante.sum()\n",
    "total0 = len(tabela_naorelevante) + b*v\n",
    "total1 = len(tabela_relevante) + b*v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidade0 = tabela_naorelevante.sum() / total_palavras\n",
    "probabilidade1 = tabela_relevante.sum() / total_palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensinando Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Classifica(tt, df):\n",
    "    \n",
    "    p_tt_dadonaorelevante = 1\n",
    "    p_tt_dadorelevante = 1\n",
    "    c = 0\n",
    "    \n",
    "    for palavra in tt:\n",
    "        \n",
    "        for a in palavra:\n",
    "    \n",
    "            if a in tabela_naorelevante:\n",
    "                p_a_dadonaorelevante = (tabela_naorelevante[a] + b) / total0\n",
    "                p_tt_dadonaorelevante *= p_a_dadonaorelevante\n",
    "            else:\n",
    "                p_a_dadonaorelevante = (b) / total0\n",
    "                p_tt_dadonaorelevante *= p_a_dadonaorelevante\n",
    "            \n",
    "            if a in tabela_relevante:\n",
    "                p_a_dadorelevante = (tabela_relevante[a] + b) / total1\n",
    "                p_tt_dadorelevante *= p_a_dadorelevante\n",
    "            else:\n",
    "                p_a_dadorelevante = (b) / total1\n",
    "                p_tt_dadorelevante *= p_a_dadorelevante\n",
    "        \n",
    "        p_tt_dadonaorelevante = p_tt_dadonaorelevante * probabilidade0\n",
    "        p_tt_dadorelevante = p_tt_dadorelevante * probabilidade1\n",
    "        \n",
    "        \n",
    "        if p_tt_dadonaorelevante > p_tt_dadorelevante:\n",
    "            df.iloc[c, 2] = 0\n",
    "        elif p_tt_dadorelevante > p_tt_dadonaorelevante:\n",
    "            df.iloc[c, 2] = 1\n",
    "            \n",
    "        c += 1\n",
    "        \n",
    "        p_tt_dadonaorelevante = 1\n",
    "        p_tt_dadorelevante = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicando a função"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Cla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>saiu da netflix? q sdd de full house! amo muit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mano, não tem mais nada p assistir na netflix ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@jornaloglobo vcs assistiram o filme, primeira...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>rt @craibeibe: inveja de você? kkkkkkkkkkkkkkk...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>quero saber quando é q vou poder colocar as pi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>@netflixbrasil netflix querida, vê se consegue...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>rt @storyiaa: never say never votou pra netfli...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>@boatosorg bolsonaristas já estão importando a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  Categoria Cla\n",
       "0    saiu da netflix? q sdd de full house! amo muit...          1   1\n",
       "1    rt @karolcaipira: gente vcs tem que entender u...          1   1\n",
       "2    rt @karolcaipira: gente vcs tem que entender u...          1   1\n",
       "3    mano, não tem mais nada p assistir na netflix ...          1   1\n",
       "4    @jornaloglobo vcs assistiram o filme, primeira...          1   1\n",
       "..                                                 ...        ...  ..\n",
       "295  rt @craibeibe: inveja de você? kkkkkkkkkkkkkkk...          0   0\n",
       "296  quero saber quando é q vou poder colocar as pi...          0   0\n",
       "297  @netflixbrasil netflix querida, vê se consegue...          1   1\n",
       "298  rt @storyiaa: never say never votou pra netfli...          1   1\n",
       "299  @boatosorg bolsonaristas já estão importando a...          0   0\n",
       "\n",
       "[300 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOTAL = []\n",
    "TOTALlimpo = train['Treinamento'].apply(cleanup)\n",
    "for a in TOTALlimpo:\n",
    "    TOTAL.append(a.split())\n",
    "\n",
    "train['Cla'] = 'esther e lila'\n",
    "\n",
    "Classifica(TOTAL, train)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora você deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>Categoria</th>\n",
       "      <th>Cla</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rt @blogdadireita: min. damares alves quer pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@rachwlgrwn no off eu fui até a terceira e se ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eu quero julie e os fantasmas na netflix pra c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nunca vou perdoar a netflix https://t.co/ssrbk...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>seria demais querer que a @damaresalves e os e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>@damaresalves pra cima desses pedófilos da net...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>to surtando com never say never na netflix mes...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>greys anatomy lançou na globo play e eu só ten...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>rt @larafurlanetto1: petição pra netflix adici...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>rt @phopha55: never say never na netflix dnv e...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Teste  Categoria Cla\n",
       "0    rt @blogdadireita: min. damares alves quer pro...          0   0\n",
       "1    @rachwlgrwn no off eu fui até a terceira e se ...          1   1\n",
       "2    eu quero julie e os fantasmas na netflix pra c...          1   0\n",
       "3    nunca vou perdoar a netflix https://t.co/ssrbk...          1   0\n",
       "4    seria demais querer que a @damaresalves e os e...          0   0\n",
       "..                                                 ...        ...  ..\n",
       "238  @damaresalves pra cima desses pedófilos da net...          1   0\n",
       "239  to surtando com never say never na netflix mes...          1   1\n",
       "240  greys anatomy lançou na globo play e eu só ten...          1   1\n",
       "241  rt @larafurlanetto1: petição pra netflix adici...          1   1\n",
       "242  rt @phopha55: never say never na netflix dnv e...          1   1\n",
       "\n",
       "[243 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testenetflixlimpo = test['Teste'].apply(cleanup)\n",
    "tt_teste = []\n",
    "for i in testenetflixlimpo:\n",
    "    tt_teste.append(i.split())\n",
    "    \n",
    "test['Cla'] = 'esther e lila'\n",
    "\n",
    "Classifica(tt_teste, test)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Categoria'] = train['Categoria'].astype('category') \n",
    "train['Cla'] = train['Cla'].astype('category') \n",
    "train['Categoria'].cat.categories = ['Irrelevante', 'Relevante']\n",
    "train['Cla'].cat.categories = ['Irrelevante', 'Relevante'] \n",
    "\n",
    "\n",
    "\n",
    "test['Categoria'] = test['Categoria'].astype('category') \n",
    "test['Cla'] = test['Cla'].astype('category') \n",
    "test['Categoria'].cat.categories = ['Irrelevante', 'Relevante'] \n",
    "test['Cla'].cat.categories = ['Irrelevante', 'Relevante']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cla</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cla          Irrelevante  Relevante\n",
       "Categoria                          \n",
       "Irrelevante         0.46   0.023333\n",
       "Relevante           0.01   0.506667"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train['Categoria'], train['Cla'], normalize = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cla</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.267490</td>\n",
       "      <td>0.168724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.353909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cla          Irrelevante  Relevante\n",
       "Categoria                          \n",
       "Irrelevante     0.267490   0.168724\n",
       "Relevante       0.209877   0.353909"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(test['Categoria'], test['Cla'], normalize = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O classificador demonstrou um bom desempenho no planilha de treinamento (96% aproximadamente), já na planilha de testes ela apresentou uma qualidade menor que o esperado (60% aproximadamente). Dessa forma, concluimos que poderia ter sido feita mais filtrações e especificações na classsificação do excel. Isso pode ser comprovado nos dados abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela cruzada Treinamento\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cla</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.01</td>\n",
       "      <td>0.506667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cla          Irrelevante  Relevante\n",
       "Categoria                          \n",
       "Irrelevante         0.46   0.023333\n",
       "Relevante           0.01   0.506667"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Tabela cruzada Treinamento')\n",
    "pd.crosstab(train['Categoria'], train['Cla'], normalize = 'all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela cruzada Teste\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Cla</th>\n",
       "      <th>Irrelevante</th>\n",
       "      <th>Relevante</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Categoria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Irrelevante</th>\n",
       "      <td>0.267490</td>\n",
       "      <td>0.168724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevante</th>\n",
       "      <td>0.209877</td>\n",
       "      <td>0.353909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Cla          Irrelevante  Relevante\n",
       "Categoria                          \n",
       "Irrelevante     0.267490   0.168724\n",
       "Relevante       0.209877   0.353909"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Tabela cruzada Teste')\n",
    "pd.crosstab(test['Categoria'], test['Cla'], normalize = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfeiçoamento:\n",
    "\n",
    "Os trabalhos vão evoluir em conceito dependendo da quantidade de itens avançados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separação de espaços entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transformações que não afetem a qualidade da informação ou classificação\n",
    "* Criar categorias intermediárias de relevância baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que não posso usar o próprio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cenários para Naïve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indicações concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza análise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propor outras formas de limpeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para o nosso projeto, seria interessante as seguintes limpezas:\n",
    "\n",
    "1- Pegar as derivações de palavras que tem o mesmo radical e contá-las como uma só palavra. Tal limpeza iria proporcionar um melhor resultado já que elas podem ter sido separadas em diferentes categorias, porém tem o mesmo significado.\n",
    "\n",
    "2- Remover acentos de palavras. Principalmente no twitter, há muitas pessoas que escrevem palavras sem acento, mas também há aquelas que escrevem com, o que pode fazer com que essas sejam contadas como palavras distintas.\n",
    "\n",
    "3- Pegar palavras e suas abreviações como por exemplo, a palavra \"que\" e sua abreviação \"q\". Tal mudança iria proporcionar uma melhoria na contabilização, ja que essas são consideradas palavras diferentes no classificador.\n",
    "\n",
    "4- Uma pessoa somente estabelecer se o tweet é relevante ou não. Apesar de o grupo ter estabelecido um padrão, quando o assunto é ler frases e classificá-las de acordo com a sua relevância, pode ser que haja diferenças por ser algo subjetivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sugestão e melhorias reais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acreditamos que para a melhoria de classificação, poderia ter sido analisada a frase como um todo e seus emojis caso apresente. Principalmente o emoji, é um bom indicador de satisfação e expressão de sentimentos, já ao analisar as frases como um todo pode-se analisar o contexto que elas estão (caso seja de ironia, sarcasmo, alegria e etc), para isso seria necessária o uso de outro sistema inclusive talvez um HTML. o material de pesquisa é de Stanford University e pode ser encontrado no link a seguir: https://web.stanford.edu/~jurafsky/slp3/4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Porque esse classificador não pode ser usado para gerar mais amostras de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro motivo de não poder usar o classificador, é porque demandaria outra planilha com o produto a ser analizado. Isso resultaria numa nova categorização da relevância e que possa ser mais ou menos complexo.\n",
    "Bom, outro problema seria em relação a ter mais ou menos tweets, caso tenha menos, a classificação dos tweets tende a ser piorada por ter menos informações e classificações.\n",
    "Por fim, ao realizar o Laplace Smoothing, nós estabelecemos uma alpha e um v que seria o número de palavras na língua portuguesa, então, caso os tweets sejam em outra língua, isso irá prejudicar os resultados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propor diferentes cenários para Naive Bayes fora do contexto do projeto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Naive Bayes poderia ser usado para classificar fake news por exemplo, dessa forma teria a possibilidade de reportar e adverttência do usuário. Tweets em relação algum outro produto, para caracterizar a satisfação ou desejo dos consumidores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#http://www.nltk.org/howto/portuguese_en.html "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
