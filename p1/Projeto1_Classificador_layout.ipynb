{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 1 - Ci√™ncia dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nome: Esther Dagir\n",
    "\n",
    "Nome: Lila Hadba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aten√ß√£o:** Ser√£o permitidos grupos de tr√™s pessoas, mas com uma rubrica mais exigente. Grupos deste tamanho precisar√£o fazer um question√°rio de avalia√ß√£o de trabalho em equipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "Carregando algumas bibliotecas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from IPython.display import display\n",
    "pd.options.display.max_rows = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "\n",
    "def cleanup(text):\n",
    "    \"\"\"\n",
    "        Fun√ß√£o de limpeza muito simples que troca alguns sinais b√°sicos por espa√ßos\n",
    "    \"\"\"\n",
    "    #import string\n",
    "    punctuation = '[!-.:?;]' # Note que os sinais [] s√£o delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    return text_subbed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Em `filename`, coloque o nome do seu arquivo de dados!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrei o arquivo Netflix.xlsx, tudo certo para prosseguir com a prova!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "filename = 'Netflix.xlsx'\n",
    "if filename in os.listdir():\n",
    "    print(f'Encontrei o arquivo {filename}, tudo certo para prosseguir com a prova!')\n",
    "else:\n",
    "    print(f'N√£o encontrei o arquivo {filename} aqui no diret√≥rio {os.getcwd()}, ser√° que voc√™ n√£o baixou o arquivo?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregando a base de dados com os tweets classificados como relevantes e n√£o relevantes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>0 irrelevante, 1 relevante, 2 muito relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>saiu da netflix? q sdd de full house! amo muit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>rt @yuki_blc: agora que one piece entrar√° no c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>mano, n√£o tem mais nada p assistir na netflix ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@jornaloglobo vcs assistiram o filme, primeira...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Treinamento  \\\n",
       "0  saiu da netflix? q sdd de full house! amo muit...   \n",
       "1  rt @karolcaipira: gente vcs tem que entender u...   \n",
       "2  rt @yuki_blc: agora que one piece entrar√° no c...   \n",
       "3  mano, n√£o tem mais nada p assistir na netflix ...   \n",
       "4  @jornaloglobo vcs assistiram o filme, primeira...   \n",
       "\n",
       "   0 irrelevante, 1 relevante, 2 muito relevante  \n",
       "0                                              1  \n",
       "1                                              1  \n",
       "2                                              0  \n",
       "3                                              2  \n",
       "4                                              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_excel(filename)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teste</th>\n",
       "      <th>0 irrelevante e 1 relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>rt @blogdadireita: min. damares alves quer pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@rachwlgrwn no off eu fui at√© a terceira e se ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>eu quero julie e os fantasmas na netflix pra c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>nunca vou perdoar a netflix https://t.co/ssrbk...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>seria demais querer que a @damaresalves e os e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Teste  \\\n",
       "0  rt @blogdadireita: min. damares alves quer pro...   \n",
       "1  @rachwlgrwn no off eu fui at√© a terceira e se ...   \n",
       "2  eu quero julie e os fantasmas na netflix pra c...   \n",
       "3  nunca vou perdoar a netflix https://t.co/ssrbk...   \n",
       "4  seria demais querer que a @damaresalves e os e...   \n",
       "\n",
       "   0 irrelevante e 1 relevante  \n",
       "0                            0  \n",
       "1                            2  \n",
       "2                            0  \n",
       "3                            2  \n",
       "4                            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_excel(filename, sheet_name = 'Teste')\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Classificador autom√°tico de sentimento\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fa√ßa aqui uma descri√ß√£o do seu produto e o que considerou como relevante ou n√£o relevante na classifica√ß√£o dos tweets.\n",
    "\n",
    "Nosso produto √© um servi√ßo de streaming de filmes e s√©ries. De uma escala de 0 a 2 temos que:\n",
    "0 √© \"nada relevante\" - abrange tweets que n√£o influenciam no desempenho da plataforma\n",
    "1 √© \"relevante\" - tweets que s√£o recomenda√ß√µes ou reinvidica√ß√µes para a plataforma\n",
    "2 √© \"muito relevante\" - todos os tweets que est√£o relacionados ao gosto positivamente e negativamente √† plataforma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>0 irrelevante, 1 relevante, 2 muito relevante</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>saiu da netflix? q sdd de full house! amo muit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>rt @karolcaipira: gente vcs tem que entender u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>@bancadadeleao tive algumas dificuldades com a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>@onepiecedadepre finalmente o melhor anime do ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>@joaopaulojm16 \"o dilema das redes\" document√°r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>280</td>\n",
       "      <td>eu s√≥ queria minha netflix de volta....üò≠</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>281</td>\n",
       "      <td>@gaudby saudade de pegar aquela filinha de lev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>283</td>\n",
       "      <td>o dilema das redes na netflix √© 10/10 e todo m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>293</td>\n",
       "      <td>netflix j√° foi melhor .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>298</td>\n",
       "      <td>rt @storyiaa: never say never votou pra netfli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Treinamento  \\\n",
       "0    saiu da netflix? q sdd de full house! amo muit...   \n",
       "1    rt @karolcaipira: gente vcs tem que entender u...   \n",
       "15   @bancadadeleao tive algumas dificuldades com a...   \n",
       "25   @onepiecedadepre finalmente o melhor anime do ...   \n",
       "26   @joaopaulojm16 \"o dilema das redes\" document√°r...   \n",
       "..                                                 ...   \n",
       "280           eu s√≥ queria minha netflix de volta....üò≠   \n",
       "281  @gaudby saudade de pegar aquela filinha de lev...   \n",
       "283  o dilema das redes na netflix √© 10/10 e todo m...   \n",
       "293                            netflix j√° foi melhor .   \n",
       "298  rt @storyiaa: never say never votou pra netfli...   \n",
       "\n",
       "     0 irrelevante, 1 relevante, 2 muito relevante  \n",
       "0                                                1  \n",
       "1                                                1  \n",
       "15                                               1  \n",
       "25                                               1  \n",
       "26                                               1  \n",
       "..                                             ...  \n",
       "280                                              1  \n",
       "281                                              1  \n",
       "283                                              1  \n",
       "293                                              1  \n",
       "298                                              1  \n",
       "\n",
       "[40 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfrelevante = train.loc[train['0 irrelevante, 1 relevante, 2 muito relevante'] == 1]\n",
    "dfrelevante\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#juntar num textao\n",
    "textao1 = \" \".join(dfrelevante.Treinamento)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Montando um Classificador Naive-Bayes\n",
    "\n",
    "Considerando apenas as mensagens da planilha Treinamento, ensine  seu classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saiu da netflix q sdd de full house amo muitooo https//tco/ux4t89lxb2 rt @karolcaipira gente vcs tem que entender uma coisa n√≥s n√£o sabemos o que realmente aconteceu pra anne ser cancelada \n",
      "a cbc n√£o quis‚Ä¶ @bancadadeleao tive algumas dificuldades com a op√ß√£o ‚Äúforward‚Äù encravou imensas vezes a app n√£o tem tanta fluidez como a app da netflix @onepiecedadepre finalmente o melhor anime do mundo aparecendo da netflix carai @joaopaulojm16 o dilema das redes document√°rio novo da netflix achei bem foda e preocupante ao mesmo tempo essa madrugada assistir a serie julie and the phantoms na netflix √© bem clich√™zinho adolescente feat high school musical adorei hahahahha rt @murislx netflix pra valorizar o trabalho dos artistas que trabalham anos se dedicando a atua√ß√£o fazendo cursos faculdade e etcü§¨ü§¨ü§¨ü§¨ü§¨‚Ä¶ agiliza n√© @netflix renewtbh https//tco/x1kz0lpfih netflix que aguente a chuva de ‚Äúcad√™ os novos epis√≥dios‚Äù colocando one piece no cat√°logo irrita me n√£o ter netflix https//tco/shepthy9gz rt @slonespp eu tentando engulir o fato que a netflix ainda n√£o renovou the umbrella academy para a 3 temporada \n",
      "\n",
      "https//tco/whi1uzbrmf rt @uolnoticias damares alves quer proibir filme da netflix acusado de sexualizar crian√ßas https//tco/uy1z2ttzze @vioietdio eu acho que n√£o vai teeeer a netflix quer tirar at√© mesmo os cigarros do sanji triste fim üò¢ rt @luccxgn meu deus warrior nun √© uma das melhores s√©ries da netflix e eles n√£o divulgam nada sobre nesse csralhoooo @jornaloglobo netflix √© campe√£ em s√©ries e filmes de conota√ß√£o sexual e pr√°ticas homossexuais  ganha da tv globo  aqui em casa n√£o assinamos @netflixbrasil mais  pirata que estica\n",
      "netflix acertou em cheio https//tco/ibqupe85md https//tco/x7bozkxywk rt @iamnanath elas fizeram tatuagem com as iniciais das personagens vc quer perder todo esse amor netflix renewtbh https//tco/mxuaova‚Ä¶ @netflixbrasil obrigada netflix te amo t√¥ chorando pq a @netflixbrasil tirou a melhor s√©rie do mundo that70show do cat√°logo\n",
      "feliz netflix eu estou chorando ok @netflixbrasil ja to chegando no ep 400 mas mesmo assim essa noticia √© perfeita  te adoro netflix @netflixbrasil netflix eu te amo dms se vcs fizerem a saga do arlong park eu choro rt @hazztomlinsom gente quando dunkirk sair na netflix a gente pode organizar aqueles neg√≥cio de assistir todo mundo junto rt @doramaticas_ a netflix aderiu o nosso  dorama vai brasilllllllllllllllllllllllllllll https//tco/s4bgmi0uy1 aqui recomendo muito um document√°rio o dilema nas redes na netflix cancelem a netflix agora s√≥ vejo disney amo a netflix mas depois disso merece um boicote https//tco/eftuc56yfl rt @renanwilbert @netflixbrasil netflix t√° ligada que pro resto da eternidade v√£o te pedir e os novos epis√≥dios de one piece n√© rt @bolsoregrets @carapanarana √© n√£o querido o filme √© uma cr√≠tica e √© muito bom recebeu pr√™mios e tudo foi muito infeliz da netflix q‚Ä¶ @toqfourze ainda acho hil√°rio que a netflix deixou desabilitado os coment√°rios do trailer no brasil s√≥ pq eles n√£o queriam dizer que plagiaram a gente kkkkk @rogwrspider eu to taaao ansiosa e a netflix n posta nada eu to agoniada @netflixbrasil vamos apoiar galera todo mundo assistindo pela netflix ai eles v√£o ver que da retorno e v√£o trazer mais eps dublados e vamos de globoplay kk fica c deuss netflix https//tco/6dt2xevndc @snowmyoongi eles nem sabem q a hist√≥ria √© daqui amg o pessoal falando q a netflix deu cr√©ditos mas tudo q eu vi falarem sobre cr√©ditos eh no ultimo episodioüíÄ deveria ser uma das primeiras coisas a aparecer no primeiro\n",
      "\n",
      "tipo baseado na serie br de mesmo nome julie and the ohantoms sla rt @ihcarioquei acho que a netflix deveria fazer uma s√©rie sobre a pol√≠tica do estado do rio de janeiro ü§¶‚Äç‚ôÇÔ∏è agora que fui perceber qui minha netflix parou do nd sendo que t√° pago kkkkk eu s√≥ queria minha netflix de voltaüò≠ @gaudby saudade de pegar aquela filinha de leve pagar 5000 numa pipoca m√©dia hahahaha\n",
      "a vibe do cinema nunca ser√° a mesma que um netflix em casa o dilema das redes na netflix √© 10/10 e todo mundo deveria ver pelo menos entender um pouco como a gente √© usado nesse sistema netflix j√° foi melhor  rt @storyiaa never say never votou pra netflix \n",
      "j√° vou separar meus lencinhos de papel https//tco/edylx1xewt\n"
     ]
    }
   ],
   "source": [
    "netflix1 = cleanup(textao1.lower())\n",
    "\n",
    "print(netflix1[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_palavras_relevantes = netflix1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       saiu\n",
       "1                         da\n",
       "2                    netflix\n",
       "3                          q\n",
       "4                        sdd\n",
       "               ...          \n",
       "679                     meus\n",
       "680                lencinhos\n",
       "681                       de\n",
       "682                    papel\n",
       "683    https//tco/edylx1xewt\n",
       "Length: 684, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "serie_1 = pd.Series(todas_palavras_relevantes)\n",
    "serie_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "netflix      38\n",
       "a            28\n",
       "que          15\n",
       "de           13\n",
       "rt           12\n",
       "             ..\n",
       "pago          1\n",
       "feat          1\n",
       "epis√≥dios     1\n",
       "irrita        1\n",
       "crian√ßas      1\n",
       "Length: 390, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_relevante = serie_1.value_counts()\n",
    "tabela_relevante\n",
    "#cancelad renov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cancelad in \"cancelado\" or \"cancelada\" or \"canceladas\" or \"cancelados\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pedofilia trocar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Verificando a performance do Classificador\n",
    "\n",
    "Agora voc√™ deve testar o seu classificador com a base de Testes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### Concluindo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Aperfei√ßoamento:\n",
    "\n",
    "Os trabalhos v√£o evoluir em conceito dependendo da quantidade de itens avan√ßados:\n",
    "\n",
    "* Limpar: \\n, :, \", ', (, ), etc SEM remover emojis\n",
    "* Corrigir separa√ß√£o de espa√ßos entre palavras e emojis ou entre emojis e emojis\n",
    "* Propor outras limpezas e transforma√ß√µes que n√£o afetem a qualidade da informa√ß√£o ou classifica√ß√£o\n",
    "* Criar categorias intermedi√°rias de relev√¢ncia baseadas na probabilidade: ex.: muito relevante, relevante, neutro, irrelevante, muito irrelevante (3 categorias: C, mais categorias conta para B)\n",
    "* Explicar por que n√£o posso usar o pr√≥prio classificador para gerar mais amostras de treinamento\n",
    "* Propor diferentes cen√°rios para Na√Øve Bayes fora do contexto do projeto\n",
    "* Sugerir e explicar melhorias reais com indica√ß√µes concretas de como implementar (indicar como fazer e indicar material de pesquisa)\n",
    "* Montar um dashboard que realiza an√°lise de sentimento e visualiza estes dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Refer√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes and Text Classification](https://arxiv.org/pdf/1410.5329.pdf)  **Mais completo**\n",
    "\n",
    "[A practical explanation of a Naive Bayes Classifier](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/) **Mais simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
